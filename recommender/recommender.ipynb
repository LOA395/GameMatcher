{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los datos de juegos (descripciones)\n",
    "df_juegos = pd.read_csv('../data_extraction/boardgames_10000_juegos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['BGGId', 'Name', 'Year_Published', 'Description', 'Min_Players',\n",
       "       'Max_Players', 'Min_Playtime', 'Max_Playtime', 'Average_Rating',\n",
       "       'Bayesian_Average_Rating', 'Number_of_Ratings', 'Mechanics',\n",
       "       'Categories'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_juegos.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener la descripción de los juegos\n",
    "df_descripciones = df_juegos[['BGGId','Name','Description', 'Mechanics', 'Categories', 'Average_Rating', 'Bayesian_Average_Rating']]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 7 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   BGGId                    10000 non-null  int64  \n",
      " 1   Name                     10000 non-null  object \n",
      " 2   Description              9992 non-null   object \n",
      " 3   Mechanics                10000 non-null  object \n",
      " 4   Categories               10000 non-null  object \n",
      " 5   Average_Rating           10000 non-null  float64\n",
      " 6   Bayesian_Average_Rating  10000 non-null  float64\n",
      "dtypes: float64(2), int64(1), object(4)\n",
      "memory usage: 547.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df_descripciones.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9992 entries, 0 to 9999\n",
      "Data columns (total 7 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   BGGId                    9992 non-null   int64  \n",
      " 1   Name                     9992 non-null   object \n",
      " 2   Description              9992 non-null   object \n",
      " 3   Mechanics                9992 non-null   object \n",
      " 4   Categories               9992 non-null   object \n",
      " 5   Average_Rating           9992 non-null   float64\n",
      " 6   Bayesian_Average_Rating  9992 non-null   float64\n",
      "dtypes: float64(2), int64(1), object(4)\n",
      "memory usage: 624.5+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Laura Ortiz\\AppData\\Local\\Temp\\ipykernel_26012\\1111501472.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_descripciones.dropna(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df_descripciones.dropna(inplace=True)\n",
    "df_descripciones.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BGGId</th>\n",
       "      <th>Name</th>\n",
       "      <th>Description</th>\n",
       "      <th>Mechanics</th>\n",
       "      <th>Categories</th>\n",
       "      <th>Average_Rating</th>\n",
       "      <th>Bayesian_Average_Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1807</th>\n",
       "      <td>62075</td>\n",
       "      <td>It Came From  the Sky</td>\n",
       "      <td>From the Publisher:&amp;#10;&amp;#10;A Living jungle a...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>6.0000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9504</th>\n",
       "      <td>165290</td>\n",
       "      <td>GRID Autosport</td>\n",
       "      <td>Grid Autosport (styled as GRID Autosport) is a...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>7.8375</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>188290</td>\n",
       "      <td>Alarums &amp; Excursions (Issue 72 - Aug 1981)</td>\n",
       "      <td>Alarums &amp; Excursions&amp;#10;Issue 72&amp;#10;August 1...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6005</th>\n",
       "      <td>86636</td>\n",
       "      <td>The Three Rings of Cassia</td>\n",
       "      <td>From publisher blurb:&amp;#10;&amp;#10;Eternally spinn...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4002</th>\n",
       "      <td>61507</td>\n",
       "      <td>Dire Heroes: Gas Attack at Ypres</td>\n",
       "      <td>The Ypres salient, a 6 mile (10 km) jut into G...</td>\n",
       "      <td>['Area Majority / Influence', 'Dice Rolling', ...</td>\n",
       "      <td>['Book', 'Expansion for Base-game', 'Wargame',...</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       BGGId                                        Name  \\\n",
       "1807   62075                       It Came From  the Sky   \n",
       "9504  165290                              GRID Autosport   \n",
       "282   188290  Alarums & Excursions (Issue 72 - Aug 1981)   \n",
       "6005   86636                   The Three Rings of Cassia   \n",
       "4002   61507            Dire Heroes: Gas Attack at Ypres   \n",
       "\n",
       "                                            Description  \\\n",
       "1807  From the Publisher:&#10;&#10;A Living jungle a...   \n",
       "9504  Grid Autosport (styled as GRID Autosport) is a...   \n",
       "282   Alarums & Excursions&#10;Issue 72&#10;August 1...   \n",
       "6005  From publisher blurb:&#10;&#10;Eternally spinn...   \n",
       "4002  The Ypres salient, a 6 mile (10 km) jut into G...   \n",
       "\n",
       "                                              Mechanics  \\\n",
       "1807                                                 []   \n",
       "9504                                                 []   \n",
       "282                                                  []   \n",
       "6005                                                 []   \n",
       "4002  ['Area Majority / Influence', 'Dice Rolling', ...   \n",
       "\n",
       "                                             Categories  Average_Rating  \\\n",
       "1807                                                 []          6.0000   \n",
       "9504                                                 []          7.8375   \n",
       "282                                                  []          0.0000   \n",
       "6005                                                 []          0.0000   \n",
       "4002  ['Book', 'Expansion for Base-game', 'Wargame',...          7.7500   \n",
       "\n",
       "      Bayesian_Average_Rating  \n",
       "1807                      0.0  \n",
       "9504                      0.0  \n",
       "282                       0.0  \n",
       "6005                      0.0  \n",
       "4002                      0.0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_descripciones.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Laura\n",
      "[nltk_data]     Ortiz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Laura\n",
      "[nltk_data]     Ortiz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "C:\\Users\\Laura Ortiz\\AppData\\Local\\Temp\\ipykernel_26012\\3183920906.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_descripciones['Descripcion_limpia'] = df_descripciones['Description'].apply(preprocesar_descripcion)\n"
     ]
    }
   ],
   "source": [
    "# Asegúrate de descargar stopwords y wordnet de nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Función mejorada de preprocesamiento de texto\n",
    "def preprocesar_descripcion(texto):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    # Eliminar entidades HTML y otros caracteres no deseados\n",
    "    texto = re.sub(r'&#?\\w+;', ' ', texto)  # Reemplazar entidades HTML como &#10; \n",
    "    texto = re.sub(r'\\W+', ' ', texto)  # Eliminar caracteres no alfanuméricos\n",
    "    texto = re.sub(r'\\d+', '', texto)  # Eliminar números\n",
    "    \n",
    "    # Convertir a minúsculas, eliminar stopwords y lematizar (solo si el texto es válido)\n",
    "    if isinstance(texto, str):\n",
    "        palabras = [lemmatizer.lemmatize(palabra) for palabra in texto.lower().split() if palabra not in stop_words]\n",
    "        return \" \".join(palabras)\n",
    "    else:\n",
    "        return \"\"  # Devolver cadena vacía si no es un texto válido\n",
    "\n",
    "# Aplicar el preprocesamiento mejorado a las descripciones\n",
    "df_descripciones['Descripcion_limpia'] = df_descripciones['Description'].apply(preprocesar_descripcion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Laura Ortiz\\AppData\\Local\\Temp\\ipykernel_26012\\2397482331.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_descripciones['Mecanicas'] = df_descripciones['Mechanics'].apply(lambda x: ', '.join(x))\n",
      "C:\\Users\\Laura Ortiz\\AppData\\Local\\Temp\\ipykernel_26012\\2397482331.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_descripciones['Categorias'] = df_descripciones['Categories'].apply(lambda x: ', '.join(x))\n",
      "C:\\Users\\Laura Ortiz\\AppData\\Local\\Temp\\ipykernel_26012\\2397482331.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_descripciones['Descripcion_completa'] = df_descripciones['Descripcion_limpia'] + \" \" + df_descripciones['Mecanicas'] + \" \" + df_descripciones['Categorias']\n"
     ]
    }
   ],
   "source": [
    "# Convertir listas de mecánicas y categorías en cadenas de texto\n",
    "df_descripciones['Mecanicas'] = df_descripciones['Mechanics'].apply(lambda x: ', '.join(x))\n",
    "df_descripciones['Categorias'] = df_descripciones['Categories'].apply(lambda x: ', '.join(x))\n",
    "\n",
    "# Combinar la descripción limpia con las mecánicas y categorías\n",
    "df_descripciones['Descripcion_completa'] = df_descripciones['Descripcion_limpia'] + \" \" + df_descripciones['Mecanicas'] + \" \" + df_descripciones['Categorias']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "# Entrenar Doc2Vec usando los índices del DataFrame como etiquetas\n",
    "documents = [TaggedDocument(doc.split(), [idx]) for idx, doc in zip(df_descripciones.index, df_descripciones['Descripcion_completa'])]\n",
    "\n",
    "# Entrenar el modelo Doc2Vec\n",
    "model = Doc2Vec(documents, vector_size=50, window=2, min_count=1, workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para recomendar juegos usando Doc2Vec y similaridad del coseno\n",
    "def recomendar_juegos_doc2vec(prompt, df_descripciones, model, top_n=5):\n",
    "    # Preprocesar el prompt y vectorizarlo usando Doc2Vec\n",
    "    prompt_vector = model.infer_vector(prompt.split())\n",
    "\n",
    "    # Obtener los vectores de todos los juegos\n",
    "    vectors = [model.dv[i] for i in range(len(df_descripciones))]\n",
    "\n",
    "    # Calcular la similaridad del coseno entre el prompt y los juegos\n",
    "    cosine_similarities = cosine_similarity([prompt_vector], vectors).flatten()\n",
    "\n",
    "    # Obtener los índices de los juegos con mayor similaridad\n",
    "    indices_recomendados = cosine_similarities.argsort()[-top_n:][::-1]\n",
    "\n",
    "    # Mostrar los juegos recomendados\n",
    "    print(\"Juegos recomendados:\")\n",
    "    for index in indices_recomendados:\n",
    "        print(f\"{df_descripciones.iloc[index]['Name']} (Similaridad: {cosine_similarities[index]:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Juegos recomendados:\n",
      "Era: The Empowered (Similaridad: 0.7521)\n",
      "Pangenre RPG Core Rules (Revised 1st Edition) (Similaridad: 0.7456)\n",
      "Plemię Ognistych Wilków (Similaridad: 0.7087)\n",
      "MadWish (Similaridad: 0.7009)\n",
      "Avalon Haunts 04 (Similaridad: 0.6965)\n"
     ]
    }
   ],
   "source": [
    "# Prompt del usuario\n",
    "prompt_usuario = 'I am looking for a game that is great for solo play and lasts about 30 minutes. I love games with a rich storytelling experience and immersive themes.'\n",
    "# Ejecutar la recomendación usando Doc2Vec\n",
    "recomendar_juegos_doc2vec(prompt_usuario, df_descripciones, model, top_n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recomendar_juegos_doc2vec_con_valoraciones(prompt, df_juegos, model, top_n=5, umbral_similaridad=0.1):\n",
    "    # Preprocesar el prompt y vectorizarlo usando Doc2Vec\n",
    "    prompt_vector = model.infer_vector(prompt.split())\n",
    "\n",
    "    # Obtener los vectores de todos los juegos usando los índices correctos del DataFrame\n",
    "    vectors = [model.dv[idx] for idx in df_juegos.index]\n",
    "\n",
    "    # Calcular la similaridad del coseno entre el prompt y los juegos\n",
    "    cosine_similarities = cosine_similarity([prompt_vector], vectors).flatten()\n",
    "\n",
    "    # Asegurarse de que las valoraciones coincidan con los juegos vectorizados\n",
    "    valoraciones = df_juegos.loc[df_juegos.index.isin(df_juegos.index), 'Average_Rating'].fillna(0).values\n",
    "\n",
    "    # Asegurar que los tamaños de cosine_similarities y valoraciones coincidan\n",
    "    if len(cosine_similarities) != len(valoraciones):\n",
    "        min_len = min(len(cosine_similarities), len(valoraciones))\n",
    "        cosine_similarities = cosine_similarities[:min_len]\n",
    "        valoraciones = valoraciones[:min_len]\n",
    "\n",
    "    # Crear una métrica combinada (similaridad * valoraciones)\n",
    "    similaridad_ponderada = cosine_similarities * valoraciones\n",
    "\n",
    "    # Filtrar recomendaciones con similaridad negativa o muy baja\n",
    "    indices_validos = [i for i, sim in enumerate(cosine_similarities) if sim > umbral_similaridad]\n",
    "\n",
    "    # Ordenar los juegos con mayor similaridad ponderada\n",
    "    indices_recomendados = sorted(indices_validos, key=lambda i: similaridad_ponderada[i], reverse=True)[:top_n]\n",
    "\n",
    "    # Mostrar los juegos recomendados\n",
    "    print(\"Juegos recomendados (con valoraciones y similaridad del coseno):\")\n",
    "    for index in indices_recomendados:\n",
    "        print(f\"{df_juegos.iloc[index]['Name']} (Similaridad ponderada: {similaridad_ponderada[index]:.4f}, \"\n",
    "              f\"Similaridad del coseno: {cosine_similarities[index]:.4f}, \"\n",
    "              f\"Valoración: {valoraciones[index]:.2f})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_usuario = 'I am looking for a game that is great for solo play and lasts about 30 minutes. I love games with a rich storytelling experience and immersive themes.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Juegos recomendados (con valoraciones y similaridad del coseno):\n",
      "Punctuation Pirates and Their Grammar Galleons (Similaridad ponderada: 6.2393, Similaridad del coseno: 0.6239, Valoración: 10.00)\n",
      "Touring Rock Band 2 (Similaridad ponderada: 5.8042, Similaridad del coseno: 0.6175, Valoración: 9.40)\n",
      "The Way to Play (Similaridad ponderada: 5.6120, Similaridad del coseno: 0.7360, Valoración: 7.62)\n",
      "OneDice Robin Hood (Similaridad ponderada: 5.4201, Similaridad del coseno: 0.6022, Valoración: 9.00)\n",
      "Wings Over the World (Similaridad ponderada: 5.3775, Similaridad del coseno: 0.5377, Valoración: 10.00)\n"
     ]
    }
   ],
   "source": [
    "# Ejecutar la recomendación usando Doc2Vec con valoraciones ponderadas y umbral\n",
    "recomendar_juegos_doc2vec_con_valoraciones(prompt_usuario, df_descripciones, model, top_n=5, umbral_similaridad=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recomendar_juegos_doc2vec_con_valoraciones(prompt, df_descripciones, model, top_n=5, umbral_similaridad=0.1, w=0.7):\n",
    "    # Preprocesar el prompt y vectorizarlo usando Doc2Vec\n",
    "    prompt_vector = model.infer_vector(prompt.split())\n",
    "\n",
    "    # Obtener los vectores de todos los juegos usando los índices correctos del DataFrame\n",
    "    vectors = [model.dv[str(idx)] for idx in df_descripciones.index]\n",
    "\n",
    "    # Calcular la similaridad del coseno entre el prompt y los juegos\n",
    "    cosine_similarities = cosine_similarity([prompt_vector], vectors).flatten()\n",
    "\n",
    "    # Asegurarse de que las valoraciones coincidan con los juegos vectorizados\n",
    "    valoraciones = df_descripciones.loc[df_descripciones.index.isin(df_descripciones.index), 'Average_Rating'].fillna(0).values\n",
    "\n",
    "    # Asegurar que los tamaños de cosine_similarities y valoraciones coincidan\n",
    "    if len(cosine_similarities) != len(valoraciones):\n",
    "        min_len = min(len(cosine_similarities), len(valoraciones))\n",
    "        cosine_similarities = cosine_similarities[:min_len]\n",
    "        valoraciones = valoraciones[:min_len]\n",
    "\n",
    "    # Crear una métrica ponderada que priorice más la similaridad del coseno\n",
    "    similaridad_ponderada = (cosine_similarities * w) + (valoraciones * (1 - w))\n",
    "\n",
    "    # Filtrar recomendaciones con similaridad negativa o muy baja\n",
    "    indices_validos = [i for i, sim in enumerate(cosine_similarities) if sim > umbral_similaridad]\n",
    "\n",
    "    # Ordenar los juegos con mayor similaridad ponderada\n",
    "    indices_recomendados = sorted(indices_validos, key=lambda i: similaridad_ponderada[i], reverse=True)[:top_n]\n",
    "\n",
    "    # Mostrar los juegos recomendados\n",
    "    print(f\"Juegos recomendados (priorizando similaridad del coseno):\")\n",
    "    for index in indices_recomendados:\n",
    "        print(f\"{df_descripciones.iloc[index]['Name']} (Similaridad ponderada: {similaridad_ponderada[index]:.4f}, \"\n",
    "              f\"Similaridad del coseno: {cosine_similarities[index]:.4f}, \"\n",
    "              f\"Valoración: {valoraciones[index]:.2f})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Key '0' not present\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_26012\\952309294.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Ejecutar la recomendación priorizando la similaridad del coseno (peso w = 0.7)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mrecomendar_juegos_doc2vec_con_valoraciones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprompt_usuario\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_descripciones\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtop_n\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mumbral_similaridad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_26012\\234191367.py\u001b[0m in \u001b[0;36mrecomendar_juegos_doc2vec_con_valoraciones\u001b[1;34m(prompt, df_descripciones, model, top_n, umbral_similaridad, w)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# Obtener los vectores de todos los juegos usando los índices correctos del DataFrame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mvectors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf_descripciones\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m# Calcular la similaridad del coseno entre el prompt y los juegos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_26012\\234191367.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# Obtener los vectores de todos los juegos usando los índices correctos del DataFrame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mvectors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf_descripciones\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m# Calcular la similaridad del coseno entre el prompt y los juegos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Anaconda\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key_or_keys)\u001b[0m\n\u001b[0;32m    401\u001b[0m         \"\"\"\n\u001b[0;32m    402\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey_or_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_KEY_TYPES\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 403\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey_or_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    404\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkey_or_keys\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Anaconda\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mget_vector\u001b[1;34m(self, key, norm)\u001b[0m\n\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m         \"\"\"\n\u001b[1;32m--> 446\u001b[1;33m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    447\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfill_norms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Anaconda\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mget_index\u001b[1;34m(self, key, default)\u001b[0m\n\u001b[0;32m    418\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 420\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Key '{key}' not present\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Key '0' not present\""
     ]
    }
   ],
   "source": [
    "# Ejecutar la recomendación priorizando la similaridad del coseno (peso w = 0.7)\n",
    "recomendar_juegos_doc2vec_con_valoraciones(prompt_usuario, df_descripciones, model, top_n=5, umbral_similaridad=0.1, w=0.7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
